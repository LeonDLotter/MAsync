<?xml version="1.0" encoding="UTF-8"?>
<struct>
    <analysis_name>ale_z_BrainSpan</analysis_name>
    <phenotype>/Users/leonlotter/MAsync/project/data/ale/ale_z.nii.gz</phenotype>
    <n_nulls>5000</n_nulls>
    <phenotype_nulls>/Users/leonlotter/MAsync/project/data/context/gcea/gcea_nullmaps_ale_z.mat</phenotype_nulls>
    <dir_result>/Users/leonlotter/MAsync/project/data/context/gcea</dir_result>
    <GCEA>
        <size_filter>1</size_filter>
        <size_filter>Inf</size_filter>
        <n_category_nulls>5000</n_category_nulls>
        <correlation_method>Spearman</correlation_method>
        <weights_quant>0.9</weights_quant>
        <weights_cutoff>true</weights_cutoff>
        <gene_coocc_thresh>0.2</gene_coocc_thresh>
        <aggregation_method>weightedmean</aggregation_method>
        <p_tail>right</p_tail>
        <p_thresh>0.05</p_thresh>
        <dataset>ABA-brainSpan-weights</dataset>
        <dataset_mat>/Users/leonlotter/projects/ABAnnotate/ABAnnotate_v1/datasets/ABA-brainSpan-weights.mat</dataset_mat>
        <category_nulls>/Users/leonlotter/projects/ABAnnotate/ABAnnotate_v1/nulls/categonulls_ABA-brainSpan-weights_ale_z_BrainSpan.mat</category_nulls>
    </GCEA>
    <atlas>/Users/leonlotter/projects/ABAnnotate/ABAnnotate_v1/atlas/Schaefer100-7_TianS1_atlas.nii</atlas>
    <n_rois>116</n_rois>
    <aba_mat>/Users/leonlotter/projects/ABAnnotate/ABAnnotate_v1/atlas/Schaefer100-7_TianS1_expression.mat</aba_mat>
    <phenotype_data>0.085159</phenotype_data>
    <phenotype_data>1.1035</phenotype_data>
    <phenotype_data>0.62873</phenotype_data>
    <phenotype_data>0.76672</phenotype_data>
    <phenotype_data>0.41228</phenotype_data>
    <phenotype_data>0.57606</phenotype_data>
    <phenotype_data>0.87629</phenotype_data>
    <phenotype_data>0.58366</phenotype_data>
    <phenotype_data>0.19706</phenotype_data>
    <phenotype_data>0.939</phenotype_data>
    <phenotype_data>0.092731</phenotype_data>
    <phenotype_data>0.34764</phenotype_data>
    <phenotype_data>0.4151</phenotype_data>
    <phenotype_data>0.55792</phenotype_data>
    <phenotype_data>0.10662</phenotype_data>
    <phenotype_data>0.71172</phenotype_data>
    <phenotype_data>1.0309</phenotype_data>
    <phenotype_data>0.24032</phenotype_data>
    <phenotype_data>0.96408</phenotype_data>
    <phenotype_data>0.39954</phenotype_data>
    <phenotype_data>0.47293</phenotype_data>
    <phenotype_data>0.68418</phenotype_data>
    <phenotype_data>0.43251</phenotype_data>
    <phenotype_data>0.14198</phenotype_data>
    <phenotype_data>0.16172</phenotype_data>
    <phenotype_data>0.99853</phenotype_data>
    <phenotype_data>0.55141</phenotype_data>
    <phenotype_data>0.48598</phenotype_data>
    <phenotype_data>0.24604</phenotype_data>
    <phenotype_data>0.43966</phenotype_data>
    <phenotype_data>0.03975</phenotype_data>
    <phenotype_data>0.094535</phenotype_data>
    <phenotype_data>0.26017</phenotype_data>
    <phenotype_data>0.79936</phenotype_data>
    <phenotype_data>0.50972</phenotype_data>
    <phenotype_data>0.75882</phenotype_data>
    <phenotype_data>0.51688</phenotype_data>
    <phenotype_data>0.33086</phenotype_data>
    <phenotype_data>0.28121</phenotype_data>
    <phenotype_data>0.73147</phenotype_data>
    <phenotype_data>0.53538</phenotype_data>
    <phenotype_data>1.008</phenotype_data>
    <phenotype_data>0.33662</phenotype_data>
    <phenotype_data>0.28963</phenotype_data>
    <phenotype_data>0.34011</phenotype_data>
    <phenotype_data>0.17956</phenotype_data>
    <phenotype_data>0.036535</phenotype_data>
    <phenotype_data>0.0070335</phenotype_data>
    <phenotype_data>0.15768</phenotype_data>
    <phenotype_data>0.6479</phenotype_data>
    <phenotype_data>0.16141</phenotype_data>
    <phenotype_data>0.82858</phenotype_data>
    <phenotype_data>0.92011</phenotype_data>
    <phenotype_data>0.66993</phenotype_data>
    <phenotype_data>0.9591</phenotype_data>
    <phenotype_data>0.76164</phenotype_data>
    <phenotype_data>0.9276</phenotype_data>
    <phenotype_data>0.47873</phenotype_data>
    <phenotype_data>0.99663</phenotype_data>
    <phenotype_data>0.25369</phenotype_data>
    <phenotype_data>0.35179</phenotype_data>
    <phenotype_data>0.58823</phenotype_data>
    <phenotype_data>0.3817</phenotype_data>
    <phenotype_data>0.45908</phenotype_data>
    <phenotype_data>0.70065</phenotype_data>
    <phenotype_data>0.051228</phenotype_data>
    <phenotype_data>1.1571</phenotype_data>
    <phenotype_data>0.91133</phenotype_data>
    <phenotype_data>0.93158</phenotype_data>
    <phenotype_data>0.79233</phenotype_data>
    <phenotype_data>0.40513</phenotype_data>
    <phenotype_data>0.72915</phenotype_data>
    <phenotype_data>0.54329</phenotype_data>
    <phenotype_data>1.8886</phenotype_data>
    <phenotype_data>0.81479</phenotype_data>
    <phenotype_data>0.90016</phenotype_data>
    <phenotype_data>0.25143</phenotype_data>
    <phenotype_data>0.38399</phenotype_data>
    <phenotype_data>0.0087546</phenotype_data>
    <phenotype_data>0.074678</phenotype_data>
    <phenotype_data>1.2899</phenotype_data>
    <phenotype_data>0.7728</phenotype_data>
    <phenotype_data>0.18835</phenotype_data>
    <phenotype_data>0.38852</phenotype_data>
    <phenotype_data>0.52712</phenotype_data>
    <phenotype_data>0.88475</phenotype_data>
    <phenotype_data>0.39251</phenotype_data>
    <phenotype_data>0.62201</phenotype_data>
    <phenotype_data>0.93908</phenotype_data>
    <phenotype_data>1.4288</phenotype_data>
    <phenotype_data>0.21946</phenotype_data>
    <phenotype_data>0.65821</phenotype_data>
    <phenotype_data>1.3644</phenotype_data>
    <phenotype_data>0.81639</phenotype_data>
    <phenotype_data>0.85183</phenotype_data>
    <phenotype_data>0.15925</phenotype_data>
    <phenotype_data>0.47301</phenotype_data>
    <phenotype_data>0.69614</phenotype_data>
    <phenotype_data>0.35003</phenotype_data>
    <phenotype_data>0.47691</phenotype_data>
    <phenotype_data>0.0069708</phenotype_data>
    <phenotype_data>0.044429</phenotype_data>
    <phenotype_data>0.3141</phenotype_data>
    <phenotype_data>0.26864</phenotype_data>
    <phenotype_data>0.19725</phenotype_data>
    <phenotype_data>0.22753</phenotype_data>
    <phenotype_data>0.17131</phenotype_data>
    <phenotype_data>0.2584</phenotype_data>
    <phenotype_data>0.149</phenotype_data>
    <phenotype_data>0.010837</phenotype_data>
    <phenotype_data>0.0756</phenotype_data>
    <phenotype_data>0.010518</phenotype_data>
    <phenotype_data>0</phenotype_data>
    <phenotype_data>0</phenotype_data>
    <phenotype_data>0.018931</phenotype_data>
    <phenotype_data>0</phenotype_data>
</struct>
